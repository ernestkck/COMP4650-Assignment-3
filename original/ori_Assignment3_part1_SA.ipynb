{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Part 1: SA\n",
    "\n",
    "### This notebook contains two sections: \n",
    "\n",
    "### 1. The first is a brief tutorial on building a simple sentiment analyser on some toy data and is not marked. \n",
    "\n",
    "### 2. The second section contains questions for you to answer and is marked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial: Sentiment Analysis on some textual data\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction and setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this tutorial is to guide you through the construction of a very basic sentiment analysis tool.\n",
    "We aim at detecting the polarity of a given text: is the attitude of the writer **positive** or **negative**.\n",
    "Texts such as `'This view is amazing'` are considered positive, whereas text as `'This view is horrible'` will be considered negative. Such a tool can be useful, for example, to detect if products reviews are positive or negative.\n",
    "The tool that we will construct starts from a very simple hypothesis: *it a text contains mainly positive words, then the general sentiment is positive; if the text contains mainly negative words, then the sentiment is negative*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** For this purpose, we will use a sentiment lexicon: a list of words together with their polarity (*i.e.*, positive or negative).\n",
    "We use the lexicon described in \n",
    "`Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, Washington, USA.`,\n",
    "and available for [download here](http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html).  \n",
    "  \n",
    "In order to speed up this tutorial, we have downloaded the lexicon and pre-treated it (*i.e.*, we removed the header).\n",
    "Save into your current folder the two lexicon files: `sentiment-lexicon-positive-words.txt` and `sentiment-lexicon-negative-words.txt` (available on Wattle).\n",
    "Please note that some words in the lexicon are intentionally misspelled in order to accommodate common errors found in social media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** We will require to verify if the words in the target text belong to the negative or to the positive lexicon.\n",
    "For this, we use the Python's powerful [NLTK (Natural Language Toolkit) module](http://www.nltk.org/).\n",
    "NLTK contains a comprehensive number of tools needed for natural text processing: tokenizers, stemmers, lemmatizers *etc.*\n",
    "In the following, we will use a tokenizer (a tool which splits natural language text into tokens - words) and a lemmatizer (a tool to reduce a word to its lemma - singular, masculine form for nouns, infinitive for verbs *etc.*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you followed the installation instructions (or if you are working on a lab computer), the *nltk* module should already be installed, alongside with the additional required data that the tokenizer requires.\n",
    "If you work on your own laptop, you need to download this additional data by executing the code below.\n",
    "This will require a download of 23.3MB.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now set up to start building our sentiment analysis tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing a basic Sentiment Analysis tool\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by initializing a set of positive and negative examples to work with. The examples were taken from [this sentiment analysis tutorial](http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = [ 'I love this cars',\n",
    "               'This view is amazing',\n",
    "\t           'I feel great this morning',\n",
    "\t           'I am so excited about the concert',\n",
    "\t           'He is my best friend']\n",
    "\n",
    "neg_tweets = ['I do not like this car',\n",
    "              'This view is horrible',\n",
    "              'I feel tired this morning',\n",
    "              'I am not looking forward to the concert',\n",
    "              'He is my worst enemy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the positive and the negative lexicons.\n",
    "The format of the lexicon files is one word per line.\n",
    "As we will lemmatize the words in the target text, we apply the same treatment to the words in the lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# define the lemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "# read the positive and negative lexicon in lists of words\n",
    "positive_words = [lmtzr.lemmatize(line.strip()) for line in open('sentiment-lexicon-positive-words.txt')]\n",
    "negative_words = [lmtzr.lemmatize(line.strip()) for line in open('sentiment-lexicon-negative-words.txt')]\n",
    "\n",
    "print(f'We have {len(positive_words)} positive words and {len(negative_words)} negative words.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to preprocess the target texts:\n",
    "* the text is split into tokens (words) by using **nltk**;\n",
    "* each token is transformed to lowercase;\n",
    "* tokens are lemmatized;\n",
    "* tokens with fewer than 3 characters are filtered out, since there are likely to be errors or non-sentiment related words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words in pos_tweets + neg_tweets:\n",
    "    # tokenize and lemmatize the current tweet\n",
    "    tokens = nltk.word_tokenize(words)\n",
    "    tweet = [lmtzr.lemmatize(x.lower()) for x in tokens if len(x) >= 3]\n",
    "    \n",
    "    # print the tweet\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, for each text we compute a score:\n",
    "* if a given word is in the positive list, we add one to the score;\n",
    "* if the word is in the negative list, we subtract one from the score.\n",
    "\n",
    "In the end, if the score is greater than zero, the text is considered as positive. \n",
    "If it is less than zero, it is considered negative. \n",
    "If it is zero, the text is considered neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code finds and outputs the positive and negative words in the texts. \n",
    "It computes the score and prints it out for each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function that computes the sentiment score\n",
    "def get_sentiment_score(text):\n",
    "    # tokenize and lemmatize the current tweet\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tweet = [lmtzr.lemmatize(x.lower()) for x in tokens if len(x) >= 3]\n",
    "\n",
    "    # calculate the sentiment score\n",
    "    score = 0\n",
    "    for word in tweet:\n",
    "        if word in positive_words:\n",
    "            score = score + 1\n",
    "            #print \"+1\", word\n",
    "        if word in negative_words:\n",
    "            score = score - 1\n",
    "            #print \"-1\", word\n",
    "    \n",
    "    return score\n",
    "\n",
    "# apply it on our example tweets\n",
    "for words in pos_tweets + neg_tweets:\n",
    "    print(f'Tweet: \"{words}\", score: {get_sentiment_score(words)}')\n",
    "    print('------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that all the positive examples have been detected as positive, because they contain positive words.\n",
    "Only 3 out of 5 negative examples were detected as such.\n",
    "In the case of *'I do not like this car'*, the word **like** is in the positive list, but in the text it is prefixed by **not** which changes the polarity.\n",
    "**like** is positive, but **not like** is negative.\n",
    "*'I am not looking forward to the concert'* does not contain any positive or negative words, even if the expression **not looking forward** has a negative connotation.\n",
    "This shows the limitations of our naive approach.\n",
    "These special cases should be taken into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Twitter dataset\n",
    "To answer the assignment questions you will run your sentiment analyse on a dataset scraped from the Twitter API. This dataset is found in the twitter-dump.json.bz2 file, where each line is a single tweet.\n",
    "\n",
    "This data can be loaded into a python dict as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2, json\n",
    "\n",
    "with bz2.BZ2File(\"./twitter-dump.json.bz2\", mode=\"r\") as reader:\n",
    "    jobj = [json.loads(line) for line in reader.readlines()]\n",
    "\n",
    "# Remove tweets with duplicate text\n",
    "unique_texts = set()\n",
    "unique_tweets = []\n",
    "for t in jobj:\n",
    "    if t['text'] in unique_texts:\n",
    "        continue\n",
    "    unique_texts.add(t['text'])\n",
    "    unique_tweets.append(t)\n",
    "jobj = unique_tweets\n",
    "    \n",
    "sample = jobj[0]\n",
    "print(json.dumps(sample, sort_keys=True, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of the different fields are described [here](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object).\n",
    "Let's take a look at some of the most important fields for our application:\n",
    "* **created_at** - represents the date at each the tweet was emitted. Here: \"2014-05-30T22:55:45.000+0200\";\n",
    "* **text** - is the actual text of the tweet. Here: \"RT @ArianaGrande: here it is y'all ...... http://t.co/ji6ETHIFuf #WatchProblemOnVEVO #problemvideo\";\n",
    "* **user** - information about the user that emitted the tweet. The field that we will be using is **id**, the id of the user. Here: '2556502655';\n",
    "* **in_reply_to_user_id** - the id of the user to which this tweets replies to. Here: null, hence this tweet is not a reply;\n",
    "* **retweeted_status** - encloses the tweet that the current tweet retweets. Here: this tweet is a retweet;\n",
    "* **YoutubeID** - the id of the Youtube video that the tweet is connected to. The text of the tweet contains a(n) (shortened) URL towards this video, such as 'iS1g8G_njx8'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> Assignment Questions (5 marks): Applying the analysis on real Twitter data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (1 point)\n",
    "\n",
    "Use the `get_sentiment_score(text)`, the sentiment scoring function defined before, and calculate the sentiment polarity of the tweets in the Twitter JSON dataset (jobj). \n",
    "Print the text of the 10 most positive tweets and the 10 most negative tweets. \n",
    "We consider that a tweet $t_1$ is more positive than another tweet $t_2$ when score of the former is higher than the score of the latter ($score(t_1) > score(t_2)$). \n",
    "Similarly, a tweet $t_1$ is more negative than $t_2$ when $score(t_1) < score(t_2)$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (1 point)\n",
    "\n",
    "Based on the scores calculated in question 1, determine and print the id of the 3 most positive users. A user $u_1$ is more positive than a user $u_2$ if the dataset contains more positive tweets emitted by $u_1$ than tweets emitted by $u_2$. Formally:\n",
    "$$ positivity(u_1) > positivity(u_2) \\iff \\left| \\left\\{ t \\, \\middle| \\, author(t) = u_1 \\wedge score(t) > 0 \\right\\} \\right| > \\left| \\left\\{ t \\, \\middle| \\, author(t) = u_2 \\wedge score(t) > 0 \\right\\} \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this dataset, some users have different format IDs, here is a function that converts them to an integer.\n",
    "def get_id(id):\n",
    "    if not isinstance(id, int):\n",
    "        id = id['$numberLong']\n",
    "    return id\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (1.5 points)\n",
    "\n",
    "### Part A (1 points)\n",
    "\n",
    "We have discussed earlier that our system is fragile to negations: it will score the expression *not beautiful* as positive because it only detects the word beautiful as positive. \n",
    "More generally, we consider that the token **not** changes the polarity of a given token: **not beautiful** becomes negative, while **not bad** becomes positive.  \n",
    "Modify the function `get_sentiment_score(text)` to detect the changes of polarity due to the token **not**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negated_sentiment_score(text):\n",
    "    raise notImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B (0.5 points)\n",
    "\n",
    "Use the new get_negated_sentiment score to find the 3 most positive users, as in question 2. Do you get different users this time, compared to your results in question 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (1.5 points)\n",
    "\n",
    "Plot the temporal evolution of the counts of positive and negative tweets. The date a tweet was emitted is found in the field *created_at*. \n",
    "Divide the temporal extent of your dataset into 100 timeslices. \n",
    "The temporal extent of the dataset is from the creation date of the first tweet to the creation date of the last tweet. \n",
    "Count how many positive and how many negative tweets you have in each timeslice. \n",
    "Plot these counts on a graphic resembling this one:\n",
    "\n",
    "![caption](files/desired-plot.png)  \n",
    "**HINT:** the graphic above is not based on real data. Your actual curves might **NOT** look like this one. Its purpose is just to show you the expected form of the graphic.\n",
    "\n",
    "**HINT:** the latest 3 tweets (3 tweets with the most recent created_at dates) are outlier dates and need to be removed, otherwise your plot will be highly skewed.\n",
    "\n",
    "**You need to** produce two plots, one `using get_sentiment_score` and one using `get_negated_sentiment_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a function which converts date strings into datetime objects.\n",
    "def get_date(date):\n",
    "    date = datetime.strptime(date['$date'], '%Y-%m-%dT%H:%M:%S.%f+0200')\n",
    "    \n",
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
